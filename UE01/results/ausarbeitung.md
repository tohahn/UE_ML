# Erste Übung, Tobias Hahn, 3073375

1. Begriffsdefinition
	1. Precision, Recall und False Positive
	Precision ist eine Kennzahl dafür wie genau ein Klassifikationsalgorithmus positive von negativen Beispielen unterscheiden kann. Besteht ein Datenset aus positiven und negativen Daten so ergibt sich die Precision aus den erkannten echt positiven Datenpunkten geteilt durch die Datenpunkte die unser Algorithmus als positiv klassifiziert. Wie man sieht verschlechtert sich die Precision dadurch dass zuviele Datenpunkte fälschlicherweise als positiv eingeteilt werden, da sich dadurch der Nenner des Bruches vergrößert und den Wert verkleinert. Ideal ist eine Precision von 1, da das bedeutet dass genausoviele Elemente als positiv klassifiziert wurden wie positiv waren. Allerdings ist das auch noch keine Garantie für eien guten Algorithmus. Erkennt unser Algorithmus nur einen Datenpunkt aus 1000 als positiv, so ist die Precision auch 1 wenn es ein echt positiver Datenpunkt ist, obwohl unser Algorithmus fast nichts erkennt. Dafür gibt es allerdings die nächste Kennzahl.
	2. Recall
	Recall ist eine Kennzahl dafür wie gut ein Klassifikationsalgorithmus positive Beispiele erkennt. Haben wir ein Datenset wie oben, so ergibt sich der Recall aus den als echt positiv erkannten Daten durch die positiven Datenpunkte aus den Ausgangsdaten. Der Recall verschlechtert sich je weniger von den positiven Datenpunkten der Algorithmus erkennt, da sich der Nenner verkleinert. Beim Recall ist also eine höhere Nummer besser, wobei das ideale Ergebnis 1 ist. Allerdings sagt der Recall alleine nichts aus: Würde unser Algorithmus darin bestehen für jeden Datenpunkt positiv auszugeben wäre der Recall 1, wir würden aber auch alle negativen Beispiele fälschlicherweise als positiv erkennen. Deswegen ergibt sich nur kombiniert aus Precision und Recall ein Wert der unseren Algorithmus gut beschreibt, das wäre der F1 Score.
	3. False Positive
	False Positive beschreibt den Typ eines von unserem Algorithmus als positiv erkannten Datenpunkts. Das False steht dafür dass der Datenpunkt gar nicht wirklich positiv ist sondern negativ, und nur von unserem Algorithmus als positiv erkannt wird. Zuviele False Positives deuten daraufhin dass unser Algorithmus zu breit eingestellt ist, also zu wenig genau. Je nach Zweck des Algorithmus kann es vorzuziehen sein viele False Positives zu haben und dafür wenig False Negatives.

2. k-Means Clustering
	1. Java Sourcecode
	2. Clustering
	Wie man anhand der beiden Abbildungen erkennen kann ist es recht wahrscheinlich dass es 3 Roboter gibt. Es gibt drei Gruppierungen von Punkten, links, mittig und rechts im Graphen. Werden nur zwei Centroide verwendet werden die beiden Gruppen mittig und rechts im Bild in einen Cluster geworfen, dies scheint jedoch anhand der Konfiguration unwahrscheinlich, da zwischen den Punkten beider Gruppen recht große Abstände vorhanden sind und gerade die Punkte in der dritten Gruppe recht nahe beieinander liegen. 
	3. Centroidauswahl
	Bei dieser Konfiguration haben wir das Problem das keiner der Punkte dem zweiten initialen Centroid zugeordnet wird da alle Punkte entweder näher zum ersten oder zum dritten Centroid sind. Damit wird kein Punkt diesem Centroid zugeordnet, und er ist für den Rest des Algorithmus unnütz.
	Eine Lösung dafür wäre für diesen Fall den Algorithmus zu modifizieren. Wird einem Centroid gar kein Punkt zugeordnet, so könnte man ihm den Punkt zuordnen der den weitesten Abstand von dem Centroid hat dem er zugeordnet wurde, da es hier wahrscheinlich ist dass sich eine andere Gruppe befindet. Damit läuft man allerdings wiederum Gefahr dass dieser Centroid einfach einen "Outlier" erwischt, also irgendeinen Punkt der sehr weit abweicht als Gruppe kennzeichnet. Um das unwahrscheinlicher zu machen könnte man statt dem weitest entfernten Punkt den zweit-, drittweitest entfernten Punkt nehmen, oder im mehrere der weiter entfernten Punkte zuweisen. Allerdings ist es bei k-Means immer so dass ein einzelner Outlier das Ergebnis sehr unschön beeinflusst.

3. Varianzclustering
	1. Was auffällt ist dass es einen Cluster mit ziemlich vielen Punkten links unten gibt, der beim Clustering in mehrere Cluster unterteilt wurde. Danaben gibt es ein paar Cluster mit ziemlich verstreuten Punkten.
	2. 38.63767077587896
	3. Das optimale Clustering ist mit vier Clustern erreicht, die Kosten (in Gummimünzen) betragen dann 27.330231073933927.
	4. Wie man an dem Plot erkennen kann gibt es nicht wirklich einen erkennbaren Zusammenhang, die Clusterings mit den höchsten Silhoutenkoeffizienten scheinen jedoch die besten zu sein.
