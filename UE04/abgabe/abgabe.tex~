\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}

\usepackage[T1]{fontenc}


\usepackage[utf8]{inputenc}
\usepackage{amsmath}

\usepackage{caption}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{listings}
\usepackage{pgfplots}
\usepackage{placeins}
\graphicspath{ {results/} }
\usepackage{forest}

\tikzset{
  treenode/.style = {shape=rectangle, rounded corners,
                     draw, align=center,
                     top color=white, bottom color=blue!20},
  root/.style     = {treenode, font=\Large, bottom color=red!30},
  env/.style      = {treenode, font=\ttfamily\normalsize},
  dummy/.style    = {circle,draw}
}

\lstset{
	basicstyle=\footnotesize,
	tabsize=3,
	title=\lstname,
	breaklines=true
}

\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\title{Machine Learning Übungsblatt 4}
\author{Ramon Leiser\and Tobias Hahn}

\begin{document}
\maketitle
\newpage
\section{Begriffsdefinitionen}

\subsection{Würfelmodell}
Um das Modell zu erstellen müssen wir zuerst einem den Würfel auswählen der den Würfel auswählt. Der W4 fällt weg, da der zuwenig Seiten hat um aus 6 Würfeln sich für einen zu entscheiden. Wir wählen daher den W6 als festlegenden Würfel. Dabei ist es so, dass die Würfel mit aufsteigender Augenzahl auch mit aufsteigender Augenzahl ausgewählt werden - also wenn 1 gewürfelt wird wird W4 angezeigt, wenn 2 gewürfelt wird W6 und so weiter. Die Zustände die wir haben sind also festgelegt durch die Würfe des W6. Diese sind unabhängig von dem vorherigen Wurf, da das bei einem Würfel so ist.

\subsubsection{Transitionsmodell}
\begin{tabular}{|c|c|}
\hline
Wurf(W6) & P(Wurf(W6)) \\\hline
1 & 1/6 \\
2 & 1/6 \\
3 & 1/6 \\
4 & 1/6 \\
5 & 1/6 \\
6 & 1/6 \\\hline
\end{tabular}
\captionof{table}{Transitionsmodell}

\paragraph{}
Das Sensormodell hat die Aufgabe, uns für einen Zustand anzugeben welche Beobachtungen wie wahrscheinlich sind. Hier ist es allgemein so, dass bei dem Zustand für den Wurf mit W6 jeweils die Augenzahlen der jeweiligen Würfel gleich wahrscheinlich sind. D.h. wenn der Zustand 1 ist, dann sind 1-4 die möglichen Beobachtungen mit jeweils ein Viertel Wahrscheinlichkeit. Die einzige Ausnahme ist Zustand 2, da sich hier der W6 selber auswählt, wir also schon wissen dass die Beobachtung 2 ist. Dementsprechend sehen die Sensormodelle so aus:

\subsubsection{Sensormodell}
\begin{tabular}{|c|c|c|}
\hline
Beobachtung x &  y & P(x|y) \\\hline
1 & 1 & 0.25\\
2 &  & 0.25 \\
3 &  & 0.25 \\
4 &  & 0.25 \\
5& & 0 \\
... & & 0\\\hline
 1& 2 & 0 \\
2 &  & 1\\
3 &  & 0\\
... &  & 0\\\hline
1 &  3& 1/8 \\
2 &  & 1/8 \\
... &  & ... \\
8&&1/8\\
9&&0\\
...&&0\\\hline
1 & 4 & 1/12 \\
2 &  & 1/12 \\
... &  & ... \\
12&&1/12\\
13&&0\\
...&&0\\\hline
1 & 5 & 1/20 \\
2 &  & 1/20 \\
... & ... & ... \\
20&&1/20\\
21&&0\\
...&&0\\\hline
1 & 6 & 1/100 \\
2 &  & 1/100 \\
... &  & ... \\
100&&1/100\\\hline
\end{tabular}
\captionof{table}{Sensormodell}

\subsection{Modulo-Würfelketten}
Ändert man die Art wie die Würfel ausgewählt werden ändern sich nur die Transitionswahrscheinlichkeiten, das Sensormodell bleibt wie zuvor. Mit dem Zustand $S_x$ codieren wir die Würfel in Zahlen von 1-6 (1-0 wegen modulo Sechs), jedoch verwenden wir die Bezeichnung $WX$ zum Teil synonym.\\
Wir haben uns entschieden Würfel, die mehr als Sechs Seiten haben mit einem Modulo wieder auf den bereich von Eins bis Sechs (bzw. $ 6\%6=0 $) zu bringen. Das fürhrt dazu dass es bei einigen Würfeln einen Überhang $U(S_x)$ gibt, der Einfluss auf die Wahrscheinlichkeiten hat. Zunächst berechnen wir jedoch wie oft die Zahlen von Eins bis Sechs in der Augenzahl $A(S_x)$ vorkommen. Dazu verwenden wir die Division ohne Rest:\\
\[ \lfloor A(S_x)/6\rfloor\]\\
Wie gesagt gibt es jedoch auch einen Überhang an Zahlen bei denen Eins zu dem vorherigen Ergebnis hinzugezählt werden muss. Er lässt sich leicht ermitteln durch die Teilung der $A(S_x)\%6$:
\begin{tabular}{|c|c|c|}\hline
\centering
$S$&Überhang ($U(S)$)&Teilung ohne Rest\\\hline
$W4$&4&0\\\hline
$W6$&0&1\\\hline
$W8$&2&1\\\hline
$W12$&0&2\\\hline
$W20$&2&2\\\hline
$W100$&4&16\\\hline
\end{tabular}
\\
Aus dieser Tabelle lassen sich die neuen Übergangswahrscheinlichkeiten ablesen. Ohne Überhänge ergibt sich die Übergangswahrscheinlichkeit aus einem Zustand durch: \\
\[ \frac{\lfloor A(S_x)/6\rfloor}{A(S_x)}\].\\
Gibt es nun jedoch einen Überhang muss man unterscheiden ob der Zustand $S_t$, in den gewechselt wird kleiner gleich dem Überhang $U(S_{t-1})$ ist. Die Komplette Formel zur Bestimmung einer Wahrscheinlichkeit $P(S_t|P_{t-1})$ lautet also: \\
\[ S_t\leq A(S_{t-1})\%6  \implies P(S \frac{\lfloor A(S_{t-1})/6\rfloor+1}{A(S_{t-1})}\]\\
\[ S_t > A(S_{t-1})\%6  \implies P(S \frac{\lfloor A(S_{t-1})/6\rfloor}{A(S_{t-1})}\]\\
\\
Das Übergangsmodell lautet also:\\
\begin{tabular}{|c|c|c|}\hline
\centering
 \small
 \setlength\tabcolsep{2pt}
 W4&W6&W8\\\hline
P(W4|W4)=1/4&P(W6|W4)=1/4&P(W8|W4)=1/4\\\hline
P(W4|W6)=1/6&P(W6|W6)=1/6&P(W8|W6)=1/6\\\hline
P(W4|W8)=1/4&P(W6|W8)=1/4&P(W8|W8)=1/8\\\hline
P(W4|W12)=1/6&P(W6|W12)=1/6&P(W8|W12)=1/6\\\hline
P(W4|W20)=1/5&P(W6|W20)=1/5&P(W8|W20)=1/20\\\hline
P(W4|W100)=17/100&P(W6|W100)=17/100&P(W8|W100)=17/100\\\hline
\\\hline
W12&W20&W100\\\hline
P(W12|W4)=1/4&P(W20|W4)=0&P(W100|W4)=0\\\hline
P(W12|W6)=1/6&P(W20|W6)=1/6&P(W100|W6)=1/6\\\hline
P(W12|W8)=1/8&P(W20|W8)=1/8&P(W100|W8)=1/8\\\hline
P(W12|W12)=1/6&P(W20|W12)=1/6&P(W100|W12)=1/6\\\hline
P(W12|W20)=1/20&P(W20|W20)=1/20&P(W100|W20)=1/20\\\hline
P(W12|W100)=17/100&P(W20|W100)=16/100&P(W100|W100)=16/100\\\hline
\end{tabular}
\subsection{Markov Kette vs. MDP}
Der Unterschied zwischen Markov Ketten und MDPs ist dass bei Markov Ketten die Zustände nur basierend auf Wahrscheinlichkeiten zu diskreten Zeitpunkten wechseln, während bei MDP's so etwas wie ein \textit{Agent} entscheidungen trifft welcher Zustand der nächste sein soll. Die Unsicherheit bleibt dennoch erhalten da der \textit{Agent} sein Ziel nur mit einer gewissen Wahrscheinlichkeit erreicht.
\subsection{Bellman-Gleichung und Value Iteration}
Die Bellman-Gleichung besagt laut der Vorlesungsfolien:\begin{quote} Wenn die Nützlichkeit eines Zustandes von den Folgezuständen abhängt, dann hängt die Nützlichkeit eines Zustandes auch von der Nützlichkeit der unmittelbaren Nachbarn ab
\end{quote}
Der Value Iteration Algorithmus durchläuft alle Zustande des MDP's und wendet auf jeden die Bellman gleichung an d.h. er inferiert die Nützlichkeit des aktuellen Zustands aus den Nachbarzuständen. Dies durchläuft nun mehrere male bis sich die Nützlichkeiten korrekt auf aulle Zustände "verteilt" haben. 
\section{Markov Ketten}
\subsection{A-priori-Wahrscheinlichkeiten}
Die A-priori-Wahrscheinlichkeiten  berechnen sich einfach aus der Divison der Anzahl eines Merkmals geteilt durch die Anzahl aller Merkmale.\\
\begin{tabular}{|c|c|c|}
\hline
G & V & U \\\hline
$\frac{4}{11} $&$ \frac{6}{11} $&$ \frac{1}{11} $\\\hline
\end{tabular}

\subsection{Vorhersage der ersten Spieltage}
Um die Markov-Kette auf zu stellen müssen zunächst die Transitionswahrscheinlichkeiten angegeben werden. Um die Transitionswahrscheinlichkeit für $P(A|B)$ zu errechnen gegeben $n_{B,A}$, der Anzahle aller Übergänge von B nach A und $n_{X,A}$ die Anzahl aller Übergänge von einem beliebigen Zustand X nach A sowie k die Anzahl der möglichen Zustände dann errechnet sich $P(A|B)$ als: \\
\[ P(A|B)= \frac{n_{X,A}}{\sum_{X=0}^k n_{X,A}} \] \\
Bei dieser Berechnung ist zu beachten, dass das erste G in der Liste der Spielergebnissen nicht mitgezählt werden kann, weil es noch keinen vorhergehenden Zustand hat.\\
Diese Rechnung soll nun ein mal exemplarisch für $P(G|G)$,$P(G|V)$ und $P(G|U)$ vorgerechnet werden. Man benötigt dafür die Anzahlen von $n_{G,G}$, $n_{U,G}$ und $n_{V,G}$ sowie die Summe $\sum_{X=0}^k n_{X,A}$ über alle k Kategorien. Wir suchen zunächst $n_{V,G}$ und markieren sie: \\
G-\textbf{V-G}-\textbf{V-G}-V-U-\textbf{V-G}-V-V\\
Es gibt also drei solcher Übergänge. Die Übergägne $n_{G,G}$ und $n_{U,G}$ sind nie zu finden:\\
G-V-G-V-G-V-U-V-G-V-V\\
Insgesamt ergibt sich also für die Anzalh der $n_{X,A}$ auch drei. Nun berechnen wir die Transitionswahrscheinlichkeit $P(G|V)$:
\[P(G|V)= \frac 3 3 = 1  \]\\
Für die anderen beiden Transitionswahrscheinlichkeiten ergibt sich:\\
 \[P(G|G)=P(G|U)= \frac 0 3 = 0  \]\\
Für die restlichen Klassen ergeben sich die folgenden Transitionswahrscheinlichkeiten:\\
\\
\begin{tabular}{|c|c|c|}
\hline
$P(G|G)=\frac{0}{3}=0$ & $P(U|G)=\frac{0}{1}=0$ & $P(V|G)=\frac{4}{6}\approx 0,6$ \\\hline
$P(G|V)=\frac{3}{3}=1$ & $P(U|V)=\frac{1}{1}=1$ & $P(V|V)=\frac{1}{6}\approx 0,2$\\\hline
$P(G|U)=\frac{0}{3}=0$ & $P(U|U)=\frac{0}{1}=0$ & $P(V|U)=\frac{1}{6}\approx 0,2$\\\hline
\end{tabular}
\\
Nun kann man in einen Baum die Möglichen Spielergebnisse eintragen. An den Kanten bezeichnet man das jeweilige Ergebniss und in den Knoten findet man die zugehörige Transitionswahrscheinlichkeit bzw. Initialwahrscheinlichkeit.\\\\
\begin{forest}
    rounded/.style={ellipse split, draw},
    squared/.style={rectangle,draw}
  [,for tree={grow'=east}
    [{\tiny P(G)=0.9}, edge label={node[midway,below,font=\scriptsize]{G}} 
    	[
    	{\tiny P(G|G)=0}, edge label={node[midway,below,font=\scriptsize]{G}}
        ] [
        {\tiny P(U|G)=0}, edge label={node[midway,below,font=\scriptsize]{U}}
        ] [
        {\tiny P(V|G)=0,66}, edge label={node[midway,below,font=\scriptsize]{V}}
        	[
    		{\tiny P(G|V)=1}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny P(U|V)=1}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|V)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ]
    ]
    [{\tiny P(V)=0.1}, edge label={node[midway,below,font=\scriptsize]{V}} 
   		 [
    	{\tiny P(G|V)=1}, edge label={node[midway,below,font=\scriptsize]{G}}
        	[
    		{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|G)=0.66}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ] [
        {\tiny P(U|V)=1}, edge label={node[midway,below,font=\scriptsize]{U}}
        	[
    		{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|U)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ] [
        {\tiny P(V|V)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	[
    		{\tiny P(G|V)=1}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny P(U|V)=1}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|V)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ] 
    ]
  ]
\end{forest}
\\
Interessiert man sich nun für die Wahrscheinlichkeiten der möglichen Ergebnisse kann man einfach den baum entlang gehen und die Wahrscheinlichkeiten aufmultiplizieren:\\
\begin{tabular}{|c|c|c|c|}
\hline
$P(G,V,G)$ & $P(G)*P(V|G)*P(G|V)$ & $0.9*\frac{4}{6}*1=$ &$0.6$\\\hline
$P(G,V,V)$ & $P(G)*P(V|G)*P(V|V)$ & $0.9*\frac{4}{6}*\frac{1}{6}=$ &$0.1$\\\hline
$P(G,V,U)$ & $P(G)*P(V|G)*P(U|V)$ & $0.9*\frac{4}{6}*1=$ &$0.6$\\\hline
$P(V,G,V)$ & $P(V)*P(G|V)*P(V|G)$ & $0.1*1*\frac{4}{6}=$ &$0.06$\\\hline
$P(V,V,G)$ & $P(V)*P(V|V)*P(G|V)$ & $0.1*\frac{1}{6}*1=$ &$0.016$\\\hline
$P(V,V,U)$ & $P(V)*P(V|V)*P(U|V)$ & $0.1*\frac{1}{6}*1=$ &$0.016$\\\hline
$P(V,V,V)$ & $P(V)*P(V|V)*P(V|V)$ & $0.1*\frac{1}{6}*\frac{1}{6}=$ &$0.003$\\\hline
$P(V,U,V)$ & $P(V)*P(U|V)*P(V|U)$ & $0.1*1*\frac{1}{6}=$ &$0.016$\\\hline

\end{tabular}
\section{Hidden Markov Modell}

\subsection{Modelle}

\begin{tabular}{|c|c|c|}
\hline
Spielstandsänderung(t) & Spielstandsänderung(t+1) & P(Spielstandsänderung(t+1)|Spielstandsänderung(t)) \\\hline
KÄ & KÄ & 0.6 \\
KÄ & TG & 0.2 \\
KÄ & TW & 0.2 \\\hline
TW & KÄ & 0.4 \\
TW & TG & 0.3 \\
TW & TW & 0.3 \\\hline
TG & KÄ & 0.4 \\
TG & TG & 0.4 \\
TG & TW & 0.2 \\\hline
\end{tabular}
\captionof{table}{Transitionsmodell}

\begin{tabular}{|c|c|c|}
\hline
Laut & Spielstandsänderung & P(Laut|Spielstandsänderung) \\\hline
Ole & KÄ & 0.8 \\
Toor & KÄ & 0.05 \\
Ohhh & KÄ & 0.15 \\\hline
Ole & TG & 0.1 \\
Toor & TG & 0.2 \\
Ohhh & TG & 0.7 \\\hline
Ole & TW & 0.1 \\
Toor & TW & 0.8 \\
Ohhh & TW & 0.1 \\\hline
\end{tabular}
\captionof{table}{Sensormodell}

\begin{tabular}{|c|c|}
\hline
Zustand & P(Zustand) \\\hline
KÄ & 0.33 \\
TG & 0.33 \\
TW & 0.33 \\\hline
\end{tabular}
\captionof{table}{A priori Wahrscheinlichkeiten}

\subsection{FORWARD-Algorithmus}
\subsubsection{Berechnungen}
\begin{lstlisting}
Calculations
P(KAE|Ole) = P(Ole|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.26664 ~= 0.824742268041
P(TW|Ole) = P(Ole|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.03333 ~= 0.103092783505
P(TG|Ole) = P(Ole|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.023331 ~= 0.0721649484536

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.825              |
+-------+--------------------+
| 1:0   | 0.103              |
+-------+--------------------+
| 0:1   | 0.072              |
+-------+--------------------+

Calculations
P(KAE|Ole) = P(Ole|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.423917525773 ~= 0.864410342653
P(TW|Ole) = P(Ole|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.0382474226804 ~= 0.0779903300399
P(TG|Ole) = P(Ole|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.0282474226804 ~= 0.0575993273071

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.713              |
+-------+--------------------+
| 1:0   | 0.153              |
+-------+--------------------+
| 0:1   | 0.110              |
+-------+--------------------+
| 2:0   | 0.008              |
+-------+--------------------+
| 1:1   | 0.012              |
+-------+--------------------+
| 0:2   | 0.004              |
+-------+--------------------+

Calculations
P(KAE|Ohhh) = P(Ohhh|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.0818646205592 ~= 0.255016109176
P(TW|Ohhh) = P(Ohhh|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.0386441034265 ~= 0.120380071771
P(TG|Ohhh) = P(Ohhh|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.200508723986 ~= 0.624603819053

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.182              |
+-------+--------------------+
| 1:0   | 0.125              |
+-------+--------------------+
| 0:1   | 0.473              |
+-------+--------------------+
| 2:0   | 0.021              |
+-------+--------------------+
| 1:1   | 0.112              |
+-------+--------------------+
| 0:2   | 0.070              |
+-------+--------------------+
| 3:0   | 0.001              |
+-------+--------------------+
| 2:1   | 0.006              |
+-------+--------------------+
| 1:2   | 0.008              |
+-------+--------------------+
| 0:3   | 0.003              |
+-------+--------------------+

Calculations
P(KAE|Ole) = P(Ole|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.241605154936 ~= 0.814292871441
P(TW|Ole) = P(Ole|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.0325501610918 ~= 0.109705292291
P(TG|Ole) = P(Ole|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.0225501610918 ~= 0.0760018362676

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.148              |
+-------+--------------------+
| 1:0   | 0.122              |
+-------+--------------------+
| 0:1   | 0.399              |
+-------+--------------------+
| 2:0   | 0.030              |
+-------+--------------------+
| 1:1   | 0.153              |
+-------+--------------------+
| 0:2   | 0.093              |
+-------+--------------------+
| 3:0   | 0.003              |
+-------+--------------------+
| 2:1   | 0.019              |
+-------+--------------------+
| 1:2   | 0.022              |
+-------+--------------------+
| 0:3   | 0.007              |
+-------+--------------------+
| 4:0   | 0.000              |
+-------+--------------------+
| 3:1   | 0.001              |
+-------+--------------------+
| 2:2   | 0.001              |
+-------+--------------------+
| 1:3   | 0.001              |
+-------+--------------------+
| 0:4   | 0.000              |
+-------+--------------------+

Calculations
P(KAE|Toor!) = P(Toor!|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.0262858574288 ~= 0.0677968291844
P(TW|Toor!) = P(Toor!|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.305143429715 ~= 0.78702994708
P(TG|Toor!) = P(Toor!|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.0562858574288 ~= 0.145173223736

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.010              |
+-------+--------------------+
| 1:0   | 0.125              |
+-------+--------------------+
| 0:1   | 0.049              |
+-------+--------------------+
| 2:0   | 0.098              |
+-------+--------------------+
| 1:1   | 0.342              |
+-------+--------------------+
| 0:2   | 0.064              |
+-------+--------------------+
| 3:0   | 0.024              |
+-------+--------------------+
| 2:1   | 0.126              |
+-------+--------------------+
| 1:2   | 0.097              |
+-------+--------------------+
| 0:3   | 0.014              |
+-------+--------------------+
| 4:0   | 0.002              |
+-------+--------------------+
| 3:1   | 0.016              |
+-------+--------------------+
| 2:2   | 0.021              |
+-------+--------------------+
| 1:3   | 0.009              |
+-------+--------------------+
| 0:4   | 0.001              |
+-------+--------------------+
| 5:0   | 0.000              |
+-------+--------------------+
| 4:1   | 0.001              |
+-------+--------------------+
| 3:2   | 0.001              |
+-------+--------------------+
| 2:3   | 0.001              |
+-------+--------------------+
| 1:4   | 0.000              |
+-------+--------------------+
| 0:5   | 0.000              |
+-------+--------------------+
\end{lstlisting}

\subsubsection{A priori Verteilung}
Die Wahl einer gleichverteilten a priori Verteilung erscheint mir sinnvoll, da man ja am Anfang nichts über das Spiel weiß und daher auch keine Annahmen darüber treffen sollte. Nun könnte man natürlich auch sagen dass man schon etwas allgemeines über das Spiel aussagen könnte, wie z.B. dass Werder Bremen eine eher schlechte Mannschaft ist, dass daher die a priori Wahrscheinlichkeit für TW niedriger, die a priori Wahrscheinlichkeit für TG eher höher angesetzt werden sollte. Andererseits könnte man behaupten dass es relativ sicher ist dass es ein Geräusch gibt wenn ein Tor fällt, dass also die Wahrscheinlichkeit für TW und TG vor dem ersten Geräusch ziemlich niedrig ist. 
\end{document}

