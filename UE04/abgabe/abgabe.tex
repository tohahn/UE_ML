\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{placeins}
\graphicspath{ {results/} }
\usepackage{forest}

\lstset{
	basicstyle=\footnotesize,
	tabsize=3,
	title=\lstname,
	breaklines=true
}

\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.75in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\title{Machine Learning Übungsblatt 4}
\author{Ramon Leiser\and Tobias Hahn}

\begin{document}
\maketitle
\newpage
\section{Begriffsdefinitionen}

\subsection{Würfelmodell}
Um das Modell zu erstellen müssen wir zuerst einem den Würfel auswählen der den Würfel auswählt. Der W4 fällt weg, da der zuwenig Seiten hat um aus 6 Würfeln sich für einen zu entscheiden. Wir wählen daher den W6 als festlegenden Würfel. Dabei ist es so, dass die Würfel mit aufsteigender Augenzahl auch mit aufsteigender Augenzahl ausgewählt werden - also wenn 1 gewürfelt wird wird W4 angezeigt, wenn 2 gewürfelt wird W6 und so weiter. Die Zustände die wir haben sind also festgelegt durch die Würfe des W6. Diese sind unabhängig von dem vorherigen Wurf, da das bei einem Würfel so ist.

\subsubsection{Transitionsmodell}
\begin{tabular}{|c|c|}
\hline
Wurf(W6) & P(Wurf(W6)) \\\hline
1 & 1/6 \\
2 & 1/6 \\
3 & 1/6 \\
4 & 1/6 \\
5 & 1/6 \\
6 & 1/6 \\\hline
\end{tabular}
\captionof{table}{Transitionsmodell}

\paragraph{}
Das Sensormodell hat die Aufgabe, uns für einen Zustand anzugeben welche Beobachtungen wie wahrscheinlich sind. Hier ist es allgemein so, dass bei dem Zustand für den Wurf mit W6 jeweils die Augenzahlen der jeweiligen Würfel gleich wahrscheinlich sind. D.h. wenn der Zustand 1 ist, dann sind 1-4 die möglichen Beobachtungen mit jeweils ein Viertel Wahrscheinlichkeit. Die einzige Ausnahme ist Zustand 2, da sich hier der W6 selber auswählt, wir also schon wissen dass die Beobachtung 2 ist. Dementsprechend sehen die Sensormodelle so aus:

\subsubsection{Sensormodell}
\begin{tabular}{|c|c|c|}
\hline
Beobachtung x & Zustand y & P(x|y) \\\hline
1 & 1 & 0.25\\
2 & 1 & 0.25 \\
3 & 1 & 0.25 \\
4 & 1 & 0.25 \\\hline
2 & 2 & 1 \\\hline
1 & 3 & 1/8 \\
2 & 3 & 1/8 \\
... & ... & ... \\\hline
1 & 4 & 1/12 \\
2 & 4 & 1/12 \\
... & ... & ... \\\hline
1 & 5 & 1/20 \\
2 & 5 & 1/20 \\
... & ... & ... \\\hline
1 & 6 & 1/100 \\
2 & 6 & 1/100 \\
... & ... & ... \\\hline
\end{tabular}
\captionof{table}{Sensormodell}


\section{Markov Ketten}
\subsection{A-priori-Wahrscheinlichkeiten}
Die A-priori-Wahrscheinlichkeiten  berechnen sich einfach aus der Divison der Anzahl eines Merkmals geteilt durch die Anzahl aller Merkmale.\\
\begin{tabular}{|c|c|c|}
\hline
G & V & U \\\hline
$\frac{4}{11} $&$ \frac{6}{11} $&$ \frac{1}{11} $\\\hline
\end{tabular}

\subsection{Vorhersage der ersten Spieltage}
Um die Markov-Kette auf zu stellen müssen zunächst die Transitionswahrscheinlichkeiten angegeben werden. Um die Transitionswahrscheinlichkeit für $P(A|B)$ zu errechnen gegeben $n_{B,A}$, der Anzahle aller Übergänge von B nach A und $n_{X,A}$ die Anzahl aller Übergänge von einem beliebigen Zustand X nach A sowie k die Anzahl der möglichen Zustände dann errechnet sich $P(A|B)$ als: \\
\[ P(A|B)= \frac{n_{X,A}}{\sum_{X=0}^k n_{X,A}} \] \\
Bei dieser Berechnung ist zu beachten, dass das erste G in der Liste der Spielergebnissen nicht mitgezählt werden kann, weil es noch keinen vorhergehenden Zustand hat.\\
Diese Rechnung soll nun ein mal exemplarisch für $P(G|G)$,$P(G|V)$ und $P(G|U)$ vorgerechnet werden. Man benötigt dafür die Anzahlen von $n_{G,G}$, $n_{U,G}$ und $n_{V,G}$ sowie die Summe $\sum_{X=0}^k n_{X,A}$ über alle k Kategorien. Wir suchen zunächst $n_{V,G}$ und markieren sie: \\
G-\textbf{V-G}-\textbf{V-G}-V-U-\textbf{V-G}-V-V\\
Es gibt also drei solcher Übergänge. Die Übergägne $n_{G,G}$ und $n_{U,G}$ sind nei zu finden:\\
G-V-G-V-G-V-U-V-G-V-V\\
Insgesamt ergibt sich also für die Anzalh der $n_{X,A}$ auch drei. Nun berechnen wir die Transitionswahrscheinlichkeit $P(G|V)$:
\[P(G|V)= \frac 3 3 = 1  \]\\
Für die anderen beiden Transitionswahrscheinlichkeiten ergibt sich:\\
 \[P(G|G)=P(G|U)= \frac 0 3 = 0  \]\\
Für die restlichen Klassen ergeben sich die folgenden Transitionswahrscheinlichkeiten:\\
\\
\begin{tabular}{|c|c|c|}
\hline
$P(G|G)=\frac{0}{3}=0$ & $P(U|G)=\frac{0}{1}=0$ & $P(V|G)=\frac{4}{6}\approx 0,6$ \\\hline
$P(G|V)=\frac{3}{3}=1$ & $P(U|V)=\frac{1}{1}=1$ & $P(V|V)=\frac{1}{6}\approx 0,2$\\\hline
$P(G|U)=\frac{0}{3}=0$ & $P(U|U)=\frac{0}{1}=0$ & $P(V|U)=\frac{1}{6}\approx 0,2$\\\hline
\end{tabular}
Nun kann man in einen Baum die Möglichen Spielergebnisse eintragen. An den Kanten bezeichnet man das jeweilige Ergebniss und in den Knoten findet man die zugehörige Transitionswahrscheinlichkeit bzw. Initialwahrscheinlichkeit.\\
\begin{forest}
    rounded/.style={ellipse split, draw},
    squared/.style={rectangle,draw}
  [,for tree={grow'=east}
    [{\tiny P(G)=0.9}, edge label={node[midway,below,font=\scriptsize]{G}} 
    	[
    	{\tiny P(G|G)=0}, edge label={node[midway,below,font=\scriptsize]{G}}
        ] [
        {\tiny P(U|G)=0}, edge label={node[midway,below,font=\scriptsize]{U}}
        ] [
        {\tiny P(V|G)=0,66}, edge label={node[midway,below,font=\scriptsize]{V}}
        	[
    		{\tiny P(G|V)=1}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny P(U|V)=1}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|V)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ]
    ]
    [{\tiny P(V)=0.1}, edge label={node[midway,below,font=\scriptsize]{V}} 
   		 [
    	{\tiny P(G|V)=1}, edge label={node[midway,below,font=\scriptsize]{G}}
        	[
    		{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|G)=0.66}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ] [
        {\tiny P(U|V)=1}, edge label={node[midway,below,font=\scriptsize]{U}}
        	[
    		{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny 0}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|U)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ] [
        {\tiny P(V|V)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	[
    		{\tiny P(G|V)=1}, edge label={node[midway,below,font=\scriptsize]{G}}
        	] [
        	{\tiny P(U|V)=1}, edge label={node[midway,below,font=\scriptsize]{U}}
        	] [
        	{\tiny P(V|V)=0.16}, edge label={node[midway,below,font=\scriptsize]{V}}
        	] 
        ] 
    ]
  ]
\end{forest}
\\
Interessiert man sich nun für die Wahrscheinlichkeiten der möglichen Ergebnisse kann man einfach den baum entlang gehen und die Wahrscheinlichkeiten aufmultiplizieren:\\
\begin{tabular}{|c|c|c|c|}
\hline
$P(G,V,G)$ & $P(G)*P(V|G)*P(G|V)$ & $0.9*\frac{4}{6}*1=$ &$0.6$\\\hline
$P(G,V,V)$ & $P(G)*P(V|G)*P(V|V)$ & $0.9*\frac{4}{6}*\frac{1}{6}=$ &$0.1$\\\hline
$P(G,V,U)$ & $P(G)*P(V|G)*P(U|V)$ & $0.9*\frac{4}{6}*1=$ &$0.6$\\\hline
$P(V,G,V)$ & $P(V)*P(G|V)*P(V|G)$ & $0.1*1*\frac{4}{6}=$ &$0.06$\\\hline
$P(V,V,G)$ & $P(V)*P(V|V)*P(G|V)$ & $0.1*\frac{1}{6}*1=$ &$0.016$\\\hline
$P(V,V,U)$ & $P(V)*P(V|V)*P(U|V)$ & $0.1*\frac{1}{6}*1=$ &$0.016$\\\hline
$P(V,V,V)$ & $P(V)*P(V|V)*P(V|V)$ & $0.1*\frac{1}{6}*\frac{1}{6}=$ &$0.003$\\\hline
$P(V,U,V)$ & $P(V)*P(U|V)*P(V|U)$ & $0.1*1*\frac{1}{6}=$ &$0.016$\\\hline

\end{tabular}


\section{Hidden Markov Modell}

\subsection{Modelle}

\begin{tabular}{|c|c|c|}
\hline
Spielstandsänderung(t) & Spielstandsänderung(t+1) & P(Spielstandsänderung(t+1)|Spielstandsänderung(t)) \\\hline
KÄ & KÄ & 0.6 \\
KÄ & TG & 0.2 \\
KÄ & TW & 0.2 \\\hline
TW & KÄ & 0.4 \\
TW & TG & 0.3 \\
TW & TW & 0.3 \\\hline
TG & KÄ & 0.4 \\
TG & TG & 0.4 \\
TG & TW & 0.2 \\\hline
\end{tabular}
\captionof{table}{Transitionsmodell}

\begin{tabular}{|c|c|c|}
\hline
Laut & Spielstandsänderung & P(Laut|Spielstandsänderung) \\\hline
Ole & KÄ & 0.8 \\
Toor & KÄ & 0.05 \\
Ohhh & KÄ & 0.15 \\\hline
Ole & TG & 0.1 \\
Toor & TG & 0.2 \\
Ohhh & TG & 0.7 \\\hline
Ole & TW & 0.1 \\
Toor & TW & 0.8 \\
Ohhh & TW & 0.1 \\\hline
\end{tabular}
\captionof{table}{Sensormodell}

\begin{tabular}{|c|c|}
\hline
Zustand & P(Zustand) \\\hline
KÄ & 0.33 \\
TG & 0.33 \\
TW & 0.33 \\\hline
\end{tabular}
\captionof{table}{A priori Wahrscheinlichkeiten}

\subsection{FORWARD-Algorithmus}
\subsubsection{Berechnungen}
\begin{lstlisting}
Calculations
P(KAE|Ole) = P(Ole|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.26664 ~= 0.824742268041
P(TW|Ole) = P(Ole|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.03333 ~= 0.103092783505
P(TG|Ole) = P(Ole|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.023331 ~= 0.0721649484536

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.825              |
+-------+--------------------+
| 1:0   | 0.103              |
+-------+--------------------+
| 0:1   | 0.072              |
+-------+--------------------+

Calculations
P(KAE|Ole) = P(Ole|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.423917525773 ~= 0.864410342653
P(TW|Ole) = P(Ole|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.0382474226804 ~= 0.0779903300399
P(TG|Ole) = P(Ole|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.0282474226804 ~= 0.0575993273071

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.713              |
+-------+--------------------+
| 1:0   | 0.153              |
+-------+--------------------+
| 0:1   | 0.110              |
+-------+--------------------+
| 2:0   | 0.008              |
+-------+--------------------+
| 1:1   | 0.012              |
+-------+--------------------+
| 0:2   | 0.004              |
+-------+--------------------+

Calculations
P(KAE|Ohhh) = P(Ohhh|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.0818646205592 ~= 0.255016109176
P(TW|Ohhh) = P(Ohhh|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.0386441034265 ~= 0.120380071771
P(TG|Ohhh) = P(Ohhh|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.200508723986 ~= 0.624603819053

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.182              |
+-------+--------------------+
| 1:0   | 0.125              |
+-------+--------------------+
| 0:1   | 0.473              |
+-------+--------------------+
| 2:0   | 0.021              |
+-------+--------------------+
| 1:1   | 0.112              |
+-------+--------------------+
| 0:2   | 0.070              |
+-------+--------------------+
| 3:0   | 0.001              |
+-------+--------------------+
| 2:1   | 0.006              |
+-------+--------------------+
| 1:2   | 0.008              |
+-------+--------------------+
| 0:3   | 0.003              |
+-------+--------------------+

Calculations
P(KAE|Ole) = P(Ole|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.241605154936 ~= 0.814292871441
P(TW|Ole) = P(Ole|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.0325501610918 ~= 0.109705292291
P(TG|Ole) = P(Ole|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.0225501610918 ~= 0.0760018362676

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.148              |
+-------+--------------------+
| 1:0   | 0.122              |
+-------+--------------------+
| 0:1   | 0.399              |
+-------+--------------------+
| 2:0   | 0.030              |
+-------+--------------------+
| 1:1   | 0.153              |
+-------+--------------------+
| 0:2   | 0.093              |
+-------+--------------------+
| 3:0   | 0.003              |
+-------+--------------------+
| 2:1   | 0.019              |
+-------+--------------------+
| 1:2   | 0.022              |
+-------+--------------------+
| 0:3   | 0.007              |
+-------+--------------------+
| 4:0   | 0.000              |
+-------+--------------------+
| 3:1   | 0.001              |
+-------+--------------------+
| 2:2   | 0.001              |
+-------+--------------------+
| 1:3   | 0.001              |
+-------+--------------------+
| 0:4   | 0.000              |
+-------+--------------------+

Calculations
P(KAE|Toor!) = P(Toor!|KAE) * (P(KAE|KAE) * P(KAE) + P(KAE|TW) * P(TW) + P(KAE|TG) * P(TG)) = 0.0262858574288 ~= 0.0677968291844
P(TW|Toor!) = P(Toor!|TW) * (P(TW|KAE) * P(KAE) + P(TW|TW) * P(TW) + P(TW|TG) * P(TG)) = 0.305143429715 ~= 0.78702994708
P(TG|Toor!) = P(Toor!|TG) * (P(TG|KAE) * P(KAE) + P(TG|TW) * P(TW) + P(TG|TG) * P(TG)) = 0.0562858574288 ~= 0.145173223736

Scores
+-------+--------------------+
| Score | Wahrscheinlichkeit |
+-------+--------------------+
| 0:0   | 0.010              |
+-------+--------------------+
| 1:0   | 0.125              |
+-------+--------------------+
| 0:1   | 0.049              |
+-------+--------------------+
| 2:0   | 0.098              |
+-------+--------------------+
| 1:1   | 0.342              |
+-------+--------------------+
| 0:2   | 0.064              |
+-------+--------------------+
| 3:0   | 0.024              |
+-------+--------------------+
| 2:1   | 0.126              |
+-------+--------------------+
| 1:2   | 0.097              |
+-------+--------------------+
| 0:3   | 0.014              |
+-------+--------------------+
| 4:0   | 0.002              |
+-------+--------------------+
| 3:1   | 0.016              |
+-------+--------------------+
| 2:2   | 0.021              |
+-------+--------------------+
| 1:3   | 0.009              |
+-------+--------------------+
| 0:4   | 0.001              |
+-------+--------------------+
| 5:0   | 0.000              |
+-------+--------------------+
| 4:1   | 0.001              |
+-------+--------------------+
| 3:2   | 0.001              |
+-------+--------------------+
| 2:3   | 0.001              |
+-------+--------------------+
| 1:4   | 0.000              |
+-------+--------------------+
| 0:5   | 0.000              |
+-------+--------------------+
\end{lstlisting}

\subsubsection{A priori Verteilung}
Die Wahl einer gleichverteilten a priori Verteilung erscheint mir sinnvoll, da man ja am Anfang nichts über das Spiel weiß und daher auch keine Annahmen darüber treffen sollte. Nun könnte man natürlich auch sagen dass man schon etwas allgemeines über das Spiel aussagen könnte, wie z.B. dass Werder Bremen eine eher schlechte Mannschaft ist, dass daher die a priori Wahrscheinlichkeit für TW niedriger, die a priori Wahrscheinlichkeit für TG eher höher angesetzt werden sollte. Andererseits könnte man behaupten dass es relativ sicher ist dass es ein Geräusch gibt wenn ein Tor fällt, dass also die Wahrscheinlichkeit für TW und TG vor dem ersten Geräusch ziemlich niedrig ist. 
\end{document}
